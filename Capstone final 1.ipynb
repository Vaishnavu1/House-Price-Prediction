{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4436e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(plt.style.available)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.style.use('seaborn-deep')\n",
    "sns.set_palette(palette='bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cbd65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_excel('House_price_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7124010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "X = df_c.drop(['price'], axis=1)\n",
    "# dependent variable\n",
    "y = df_c['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426953fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                    float64\n",
       "room_bed                 float64\n",
       "room_bath                float64\n",
       "ceil                     float64\n",
       "sight                      int64\n",
       "ceil_measure             float64\n",
       "basement                 float64\n",
       "living_measure15         float64\n",
       "lot_measure15            float64\n",
       "total_area               float64\n",
       "years_old                float64\n",
       "coast_1.0                  int64\n",
       "furnished_1.0              int64\n",
       "location_Bellevue          int64\n",
       "location_Covington         int64\n",
       "location_Federal Way       int64\n",
       "location_Issaquah          int64\n",
       "location_Kent              int64\n",
       "location_Kirkland          int64\n",
       "location_Maple Valley      int64\n",
       "location_Others            int64\n",
       "location_Redmond           int64\n",
       "location_Renton            int64\n",
       "location_Sammamish         int64\n",
       "location_Seattle           int64\n",
       "is_renovated_1             int64\n",
       "condition_2.0              int64\n",
       "condition_3.0              int64\n",
       "condition_4.0              int64\n",
       "condition_5.0              int64\n",
       "quality_2                  int64\n",
       "quality_3                  int64\n",
       "quality_4                  int64\n",
       "quality_5                  int64\n",
       "quality_6                  int64\n",
       "quality_7                  int64\n",
       "quality_8                  int64\n",
       "quality_9                  int64\n",
       "quality_10                 int64\n",
       "quality_11                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f4826",
   "metadata": {},
   "source": [
    "## Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f561ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac55dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9eab1",
   "metadata": {},
   "source": [
    "### SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b367dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Model Performance:\n",
      "Train MSE: 0.1636\n",
      "Train RMSE: 0.4044\n",
      "Train MAE: 0.2382\n",
      "Train MAPE: 0.488\n",
      "Train R2: 0.8359\n",
      "\n",
      "Test MSE: 0.2027\n",
      "Test RMSE: 0.4502\n",
      "Test MAE: 0.2686\n",
      "Test MAPE: 0.5183\n",
      "Test R2: 0.7987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Create an instance of SVR\n",
    "svr = SVR()\n",
    "\n",
    "# Fit the SVR model to the training data\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions_svr = svr.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_svr = svr.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the training set\n",
    "train_mse_svr = mean_squared_error(y_train, train_predictions_svr)\n",
    "train_rmse_svr = np.sqrt(train_mse_svr)\n",
    "train_mae_svr = mean_absolute_error(y_train, train_predictions_svr)\n",
    "train_mape_svr = np.sqrt(mean_absolute_error(y_train, train_predictions_svr))\n",
    "train_r2_svr = r2_score(y_train, train_predictions_svr)\n",
    "\n",
    "# Calculate performance metrics for the test set\n",
    "test_mse_svr = mean_squared_error(y_test, test_predictions_svr)\n",
    "test_rmse_svr = np.sqrt(test_mse_svr)\n",
    "test_mae_svr = mean_absolute_error(y_test, test_predictions_svr)\n",
    "test_mape_svr = np.sqrt(mean_absolute_error(y_test, test_predictions_svr))\n",
    "test_r2_svr = r2_score(y_test, test_predictions_svr)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"SVR Model Performance:\")\n",
    "print(\"Train MSE:\", round(train_mse_svr, 4))\n",
    "print(\"Train RMSE:\", round(train_rmse_svr, 4))\n",
    "print(\"Train MAE:\", round(train_mae_svr, 4))\n",
    "print(\"Train MAPE:\", round(train_mape_svr, 4))\n",
    "print(\"Train R2:\", round(train_r2_svr, 4))\n",
    "print()\n",
    "print(\"Test MSE:\", round(test_mse_svr, 4))\n",
    "print(\"Test RMSE:\", round(test_rmse_svr, 4))\n",
    "print(\"Test MAE:\", round(test_mae_svr, 4))\n",
    "print(\"Test MAPE:\", round(test_mape_svr, 4))\n",
    "print(\"Test R2:\", round(test_r2_svr, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c387174",
   "metadata": {},
   "source": [
    "### Hyper tuned SVR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f805475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (SVR): {'C': 1, 'epsilon': 0.1, 'kernel': 'rbf'}\n",
      "SVR Model Performance:\n",
      "Train MSE: 0.1636\n",
      "Train RMSE: 0.4044\n",
      "Train MAE: 0.2382\n",
      "Train MAPE: 0.488\n",
      "Train R2: 0.8359\n",
      "\n",
      "Test MSE: 0.2027\n",
      "Test RMSE: 0.4502\n",
      "Test MAE: 0.2686\n",
      "Test MAPE: 0.5183\n",
      "Test R2: 0.7987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'epsilon': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Create an instance of SVR\n",
    "svr = SVR()\n",
    "\n",
    "# Perform Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_svr = grid_search.best_params_\n",
    "best_model_svr = grid_search.best_estimator_\n",
    "\n",
    "# Fit the SVR model with the best hyperparameters to the training data\n",
    "best_model_svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions_svr = best_model_svr.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_svr = best_model_svr.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the training set\n",
    "train_mse_svr = mean_squared_error(y_train, train_predictions_svr)\n",
    "train_rmse_svr = np.sqrt(train_mse_svr)\n",
    "train_mae_svr = mean_absolute_error(y_train, train_predictions_svr)\n",
    "train_mape_svr = np.sqrt(mean_absolute_error(y_train, train_predictions_svr))\n",
    "train_r2_svr = r2_score(y_train, train_predictions_svr)\n",
    "\n",
    "# Calculate performance metrics for the test set\n",
    "test_mse_svr = mean_squared_error(y_test, test_predictions_svr)\n",
    "test_rmse_svr = np.sqrt(test_mse_svr)\n",
    "test_mae_svr = mean_absolute_error(y_test, test_predictions_svr)\n",
    "test_mape_svr = np.sqrt(mean_absolute_error(y_test, test_predictions_svr))\n",
    "test_r2_svr = r2_score(y_test, test_predictions_svr)\n",
    "\n",
    "# Print the best hyperparameters and performance metrics\n",
    "print(\"Best Hyperparameters (SVR):\", best_params_svr)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"SVR Model Performance:\")\n",
    "print(\"Train MSE:\", round(train_mse_svr, 4))\n",
    "print(\"Train RMSE:\", round(train_rmse_svr, 4))\n",
    "print(\"Train MAE:\", round(train_mae_svr, 4))\n",
    "print(\"Train MAPE:\", round(train_mape_svr, 4))\n",
    "print(\"Train R2:\", round(train_r2_svr, 4))\n",
    "print()\n",
    "print(\"Test MSE:\", round(test_mse_svr, 4))\n",
    "print(\"Test RMSE:\", round(test_rmse_svr, 4))\n",
    "print(\"Test MAE:\", round(test_mae_svr, 4))\n",
    "print(\"Test MAPE:\", round(test_mape_svr, 4))\n",
    "print(\"Test R2:\", round(test_r2_svr, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11745898",
   "metadata": {},
   "source": [
    "## XGB REGRESSOR BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2e32aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE (XGBRegressor): 0.1865\n",
      "Train MAPE (XGBRegressor): 0.4319\n",
      "Train MSE (XGBRegressor): 0.0712\n",
      "Train RMSE (XGBRegressor): 0.2668\n",
      "Train R2 (XGBRegressor): 0.9286\n",
      "Test MAE (XGBRegressor): 0.2715\n",
      "Test MAPE (XGBRegressor): 0.5211\n",
      "Test MSE (XGBRegressor): 0.1844\n",
      "Test RMSE (XGBRegressor): 0.4294\n",
      "Test R2 (XGBRegressor): 0.8169\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Create an instance of XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions_xgb = xgb_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for train set\n",
    "train_mae_xgb = mean_absolute_error(y_train, train_predictions_xgb)\n",
    "train_mape_xgb = np.sqrt(mean_absolute_error(y_train, train_predictions_xgb))\n",
    "train_mse_xgb = mean_squared_error(y_train, train_predictions_xgb)\n",
    "train_rmse_xgb = np.sqrt(train_mse_xgb)\n",
    "train_r2_xgb = r2_score(y_train, train_predictions_xgb)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_mae_xgb = mean_absolute_error(y_test, test_predictions_xgb)\n",
    "test_mape_xgb = np.sqrt(mean_absolute_error(y_test, test_predictions_xgb))\n",
    "test_mse_xgb = mean_squared_error(y_test, test_predictions_xgb)\n",
    "test_rmse_xgb = np.sqrt(test_mse_xgb)\n",
    "test_r2_xgb = r2_score(y_test, test_predictions_xgb)\n",
    "\n",
    "# Print the train results\n",
    "print(\"Train MAE (XGBRegressor):\", round(train_mae_xgb, 4))\n",
    "print(\"Train MAPE (XGBRegressor):\", round(train_mape_xgb, 4))\n",
    "print(\"Train MSE (XGBRegressor):\", round(train_mse_xgb, 4))\n",
    "print(\"Train RMSE (XGBRegressor):\", round(train_rmse_xgb, 4))\n",
    "print(\"Train R2 (XGBRegressor):\", round(train_r2_xgb, 4))\n",
    "\n",
    "# Print the test results\n",
    "print(\"Test MAE (XGBRegressor):\", round(test_mae_xgb, 4))\n",
    "print(\"Test MAPE (XGBRegressor):\", round(test_mape_xgb, 4))\n",
    "print(\"Test MSE (XGBRegressor):\", round(test_mse_xgb, 4))\n",
    "print(\"Test RMSE (XGBRegressor):\", round(test_rmse_xgb, 4))\n",
    "print(\"Test R2 (XGBRegressor):\", round(test_r2_xgb, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929cf0d",
   "metadata": {},
   "source": [
    "## XGB REGRESSOR TUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308c3cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (XGBRegressor): {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Train MAE (XGBRegressor): 0.2173\n",
      "Train MAPE (XGBRegressor): 0.4661\n",
      "Train MSE (XGBRegressor): 0.0987\n",
      "Train RMSE (XGBRegressor): 0.3142\n",
      "Train R2 (XGBRegressor): 0.901\n",
      "Test MAE (XGBRegressor): 0.2657\n",
      "Test MAPE (XGBRegressor): 0.5155\n",
      "Test MSE (XGBRegressor): 0.1752\n",
      "Test RMSE (XGBRegressor): 0.4186\n",
      "Test R2 (XGBRegressor): 0.826\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Create an instance of XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'reg_alpha': [0.01, 0.1, 1],\n",
    "    'reg_lambda': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Perform Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_xgb = grid_search.best_params_\n",
    "best_model_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions_xgb = best_model_xgb.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_xgb = best_model_xgb.predict(X_test)\n",
    "\n",
    "# Calculate metrics for train set\n",
    "train_mae_xgb = mean_absolute_error(y_train, train_predictions_xgb)\n",
    "train_mape_xgb = np.sqrt(mean_absolute_error(y_train, train_predictions_xgb))\n",
    "train_mse_xgb = mean_squared_error(y_train, train_predictions_xgb)\n",
    "train_rmse_xgb = np.sqrt(train_mse_xgb)\n",
    "train_r2_xgb = r2_score(y_train, train_predictions_xgb)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_mae_xgb = mean_absolute_error(y_test, test_predictions_xgb)\n",
    "test_mape_xgb = np.sqrt(mean_absolute_error(y_test, test_predictions_xgb))\n",
    "test_mse_xgb = mean_squared_error(y_test, test_predictions_xgb)\n",
    "test_rmse_xgb = np.sqrt(test_mse_xgb)\n",
    "test_r2_xgb = r2_score(y_test, test_predictions_xgb)\n",
    "\n",
    "# Print the best hyperparameters and metrics\n",
    "print(\"Best Hyperparameters (XGBRegressor):\", best_params_xgb)\n",
    "\n",
    "# Print the train results\n",
    "print(\"Train MAE (XGBRegressor):\", round(train_mae_xgb, 4))\n",
    "print(\"Train MAPE (XGBRegressor):\", round(train_mape_xgb, 4))\n",
    "print(\"Train MSE (XGBRegressor):\", round(train_mse_xgb, 4))\n",
    "print(\"Train RMSE (XGBRegressor):\", round(train_rmse_xgb, 4))\n",
    "print(\"Train R2 (XGBRegressor):\", round(train_r2_xgb, 4))\n",
    "\n",
    "# Print the test results\n",
    "print(\"Test MAE (XGBRegressor):\", round(test_mae_xgb, 4))\n",
    "print(\"Test MAPE (XGBRegressor):\", round(test_mape_xgb, 4))\n",
    "print(\"Test MSE (XGBRegressor):\", round(test_mse_xgb, 4))\n",
    "print(\"Test RMSE (XGBRegressor):\", round(test_rmse_xgb, 4))\n",
    "print(\"Test R2 (XGBRegressor):\", round(test_r2_xgb, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808cc7f7",
   "metadata": {},
   "source": [
    "## RF REGRESSOR TUNED MODEL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4ed869d",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the Random Forest model\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_rf = grid_search.best_params_\n",
    "best_model_rf = grid_search.best_estimator_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions_rf = best_model_rf.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_rf = best_model_rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics for train set\n",
    "train_mse_rf = mean_squared_error(y_train, train_predictions_rf)\n",
    "train_rmse_rf = np.sqrt(train_mse_rf)\n",
    "train_mae_rf = mean_absolute_error(y_train, train_predictions_rf)\n",
    "train_r2_rf = r2_score(y_train, train_predictions_rf)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_mse_rf = mean_squared_error(y_test, test_predictions_rf)\n",
    "test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "test_mae_rf = mean_absolute_error(y_test, test_predictions_rf)\n",
    "test_r2_rf = r2_score(y_test, test_predictions_rf)\n",
    "\n",
    "# Print the best hyperparameters and metrics\n",
    "print(\"Best Hyperparameters (Random Forest):\", best_params_rf)\n",
    "\n",
    "# Print the train results\n",
    "print(\"Train MSE (Random Forest):\", train_mse_rf)\n",
    "print(\"Train RMSE (Random Forest):\", train_rmse_rf)\n",
    "print(\"Train MAE (Random Forest):\", train_mae_rf)\n",
    "print(\"Train R2 (Random Forest):\", train_r2_rf)\n",
    "\n",
    "# Print the test results\n",
    "print(\"Test MSE (Random Forest):\", test_mse_rf)\n",
    "print(\"Test RMSE (Random Forest):\", test_rmse_rf)\n",
    "print(\"Test MAE (Random Forest):\", test_mae_rf)\n",
    "print(\"Test R2 (Random Forest):\", test_r2_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae4a84",
   "metadata": {},
   "source": [
    "### RF TUNED MODEL ACTUAL VS PREDICTED SCATTER PLOT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8e1338f",
   "metadata": {},
   "source": [
    "# Scatter plot for train set\n",
    "plt.scatter(y_train, train_predictions_rf, label='Train Data')\n",
    "# Scatter plot for test set\n",
    "plt.scatter(y_test, test_predictions_rf, label='Test Data')\n",
    "# Add diagonal line\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], 'r--')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Scatter Plot: Actual vs. Predicted Values (R2={:.2f})'.format(test_r2_rf))\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc6607",
   "metadata": {},
   "source": [
    "## BOOSTING REGRESSOR BASE MODEL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fcd6633",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Boosting model\n",
    "boost_train_predictions = best_model_xgb.predict(X_train)\n",
    "boost_test_predictions = best_model_xgb.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted for training set (Boosting)\n",
    "ax1.scatter(y_train, boost_train_predictions, color='blue')\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=2)\n",
    "ax1.set_xlabel('Actual')\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax1.set_title('Boosting Model - Training Set')\n",
    "\n",
    "# Plot actual vs predicted for test set (Boosting)\n",
    "ax2.scatter(y_test, boost_test_predictions, color='red')\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax2.set_xlabel('Actual')\n",
    "ax2.set_ylabel('Predicted')\n",
    "ax2.set_title('Boosting Model - Test Set')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141a666",
   "metadata": {},
   "source": [
    "## Bagging regressor hyper tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec3dd41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Bagging Regression): {'max_features': 0.9, 'max_samples': 0.7, 'n_estimators': 300}\n",
      "Train MAE (Bagging Regression): 0.13898238015986641\n",
      "Train MAPE (Bagging Regression): 0.3728034068512068\n",
      "Train MSE (Bagging Regression): 0.05153041111456656\n",
      "Train RMSE (Bagging Regression): 0.2270031081605857\n",
      "Train R2 (Bagging Regression): 0.9483121375801444\n",
      "Test MAE (Bagging Regression): 0.2723203394328679\n",
      "Test MAPE (Bagging Regression): 0.521843213458667\n",
      "Test MSE (Bagging Regression): 0.1951580649321646\n",
      "Test RMSE (Bagging Regression): 0.4417669803552146\n",
      "Test R2 (Bagging Regression): 0.8061584759849227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Create the Bagging Regression model\n",
    "bagging_model = BaggingRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_samples': [0.5, 0.7, 0.9],\n",
    "    'max_features': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Perform Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_bagging = grid_search.best_params_\n",
    "best_model_bagging = grid_search.best_estimator_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "train_predictions_bagging = best_model_bagging.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_bagging = best_model_bagging.predict(X_test)\n",
    "\n",
    "# Calculate metrics for train set\n",
    "train_mae_bagging = mean_absolute_error(y_train, train_predictions_bagging)\n",
    "train_mape_bagging = np.sqrt(mean_absolute_error(y_train, train_predictions_bagging))\n",
    "train_mse_bagging = mean_squared_error(y_train, train_predictions_bagging)\n",
    "train_rmse_bagging = np.sqrt(train_mse_bagging)\n",
    "train_r2_bagging = r2_score(y_train, train_predictions_bagging)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_mae_bagging = mean_absolute_error(y_test, test_predictions_bagging)\n",
    "test_mape_bagging = np.sqrt(mean_absolute_error(y_test, test_predictions_bagging))\n",
    "test_mse_bagging = mean_squared_error(y_test, test_predictions_bagging)\n",
    "test_rmse_bagging = np.sqrt(test_mse_bagging)\n",
    "test_r2_bagging = r2_score(y_test, test_predictions_bagging)\n",
    "\n",
    "# Print the best hyperparameters and metrics\n",
    "print(\"Best Hyperparameters (Bagging Regression):\", best_params_bagging)\n",
    "\n",
    "# Print the train results\n",
    "print(\"Train MAE (Bagging Regression):\", train_mae_bagging)\n",
    "print(\"Train MAPE (Bagging Regression):\", train_mape_bagging)\n",
    "print(\"Train MSE (Bagging Regression):\", train_mse_bagging)\n",
    "print(\"Train RMSE (Bagging Regression):\", train_rmse_bagging)\n",
    "print(\"Train R2 (Bagging Regression):\", train_r2_bagging)\n",
    "\n",
    "# Print the test results\n",
    "print(\"Test MAE (Bagging Regression):\", test_mae_bagging)\n",
    "print(\"Test MAPE (Bagging Regression):\", test_mape_bagging)\n",
    "print(\"Test MSE (Bagging Regression):\", test_mse_bagging)\n",
    "print(\"Test RMSE (Bagging Regression):\", test_rmse_bagging)\n",
    "print(\"Test R2 (Bagging Regression):\", test_r2_bagging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945650c0",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed74545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "031c06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Train MAE: 0.3445648423093868\n",
      "Test MAE: 0.33939630025042095\n",
      "Train MSE: 0.2684411171563523\n",
      "Test MSE: 0.26169021881243343\n",
      "Train RMSE: 0.5181130351152655\n",
      "Test RMSE: 0.5115566623673603\n",
      "Train R2: 0.7307386603114516\n",
      "Test R2: 0.7400751495867043\n",
      "Train MAPE: 268.94823162407016\n",
      "Test MAPE: 252.68368529351793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "linear_regression_predictions_train = regression_model.predict(X_train)\n",
    "linear_regression_predictions_test = regression_model.predict(X_test)\n",
    "linear_regression_mae_train = mean_absolute_error(y_train, linear_regression_predictions_train)\n",
    "linear_regression_mae_test = mean_absolute_error(y_test, linear_regression_predictions_test)\n",
    "linear_regression_mse_train = mean_squared_error(y_train, linear_regression_predictions_train)\n",
    "linear_regression_mse_test = mean_squared_error(y_test, linear_regression_predictions_test)\n",
    "linear_regression_r2_train = r2_score(y_train, linear_regression_predictions_train)\n",
    "linear_regression_r2_test = r2_score(y_test, linear_regression_predictions_test)\n",
    "linear_regression_rmse_train = np.sqrt(mean_squared_error(y_train, linear_regression_predictions_train))\n",
    "linear_regression_rmse_test = np.sqrt(mean_squared_error(y_test, linear_regression_predictions_test))\n",
    "linear_regression_mape_train = np.mean(np.abs((y_train - linear_regression_predictions_train) / y_train)) * 100\n",
    "linear_regression_mape_test = np.mean(np.abs((y_test - linear_regression_predictions_test) / y_test)) * 100\n",
    "print(\"Linear Regression:\")\n",
    "print(\"Train MAE:\", linear_regression_mae_train)\n",
    "print(\"Test MAE:\", linear_regression_mae_test)\n",
    "print(\"Train MSE:\", linear_regression_mse_train)\n",
    "print(\"Test MSE:\", linear_regression_mse_test)\n",
    "print(\"Train RMSE:\", linear_regression_rmse_train)\n",
    "print(\"Test RMSE:\", linear_regression_rmse_test)\n",
    "print(\"Train R2:\", linear_regression_r2_train)\n",
    "print(\"Test R2:\", linear_regression_r2_test)\n",
    "print(\"Train MAPE:\", linear_regression_mape_train)\n",
    "print(\"Test MAPE:\", linear_regression_mape_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dce4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5d2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0648dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m base_models \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mbest_model_rf\u001b[49m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_xgb), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBagging Regressor\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_bagging)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model_rf' is not defined"
     ]
    }
   ],
   "source": [
    "base_models = [('Random Forest', best_model_rf), ('XGBoost', best_model_xgb), ('Bagging Regressor', best_model_bagging)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = best_model_xgb  # You can choose any of the base models as the meta-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "stacked_model.fit(X_train, y_train)\n",
    "train_predictions_stacked = stacked_model.predict(X_train)\n",
    "test_predictions_stacked = stacked_model.predict(X_test)\n",
    "train_mse_stacked = mean_squared_error(y_train, train_predictions_stacked)\n",
    "train_rmse_stacked = np.sqrt(train_mse_stacked)\n",
    "train_mae_stacked = mean_absolute_error(y_train, train_predictions_stacked)\n",
    "train_mape_stacked = np.sqrt(mean_absolute_error(y_train, train_predictions_stacked))\n",
    "train_r2_stacked = r2_score(y_train, train_predictions_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_stacked = mean_squared_error(y_test, test_predictions_stacked)\n",
    "test_rmse_stacked = np.sqrt(test_mse_stacked)\n",
    "test_mae_stacked = mean_absolute_error(y_test, test_predictions_stacked)\n",
    "test_mpe_stacked = np.sqrt(mean_absolute_error(y_test, test_predictions_stacked))\n",
    "test_r2_stacked = r2_score(y_test, test_predictions_stacked)\n",
    "print(\"Stacked Model Performance:\")\n",
    "print(\"Train MSE:\", train_mse_stacked)\n",
    "print(\"Train RMSE:\", train_rmse_stacked)\n",
    "print(\"Train MAE:\", train_mae_stacked)\n",
    "print(\"Train MAPE:\", train_mape_stacked)\n",
    "print(\"Train R2:\", train_r2_stacked)\n",
    "print()\n",
    "print(\"Test MSE:\", test_mse_stacked)\n",
    "print(\"Test RMSE:\", test_rmse_stacked)\n",
    "print(\"Test MAE:\", test_mae_stacked)\n",
    "print(\"Test MAPE:\", test_mape_stacked)\n",
    "print(\"Test R2:\", test_r2_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa81ba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Performance:\n",
      "Train MSE: 0.0970057851058944\n",
      "Train RMSE: 0.3114575173372677\n",
      "Train MAE: 0.20903309991227517\n",
      "Train MAPE: 0.4572013778547427\n",
      "Train R2: 0.9026978134652184\n",
      "\n",
      "Test MSE: 0.17063933777287021\n",
      "Test RMSE: 0.41308514591167544\n",
      "Test MAE: 0.26116582917543274\n",
      "Test MAPE: 0.5110438622813435\n",
      "Test R2: 0.8305117992314897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('xgb', best_model_xgb),\n",
    "    ('bagging', best_model_bagging),\n",
    "    ('Linear Reg',regression_model),\n",
    "    ('SVR',best_model_svr)\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the stacked model with regularization\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Fit the stacked model to the training data\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions_stacked = stacked_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the training set\n",
    "train_mse_stacked = mean_squared_error(y_train, train_predictions_stacked)\n",
    "train_rmse_stacked = np.sqrt(train_mse_stacked)\n",
    "train_mae_stacked = mean_absolute_error(y_train, train_predictions_stacked)\n",
    "train_mape_stacked = np.sqrt(mean_absolute_error(y_train, train_predictions_stacked))\n",
    "train_r2_stacked = r2_score(y_train, train_predictions_stacked)\n",
    "\n",
    "\n",
    "# Calculate performance metrics for the test set\n",
    "test_mse_stacked = mean_squared_error(y_test, test_predictions_stacked)\n",
    "test_rmse_stacked = np.sqrt(test_mse_stacked)\n",
    "test_mae_stacked = mean_absolute_error(y_test, test_predictions_stacked)\n",
    "test_mape_stacked = np.sqrt(mean_absolute_error(y_test, test_predictions_stacked))\n",
    "test_r2_stacked = r2_score(y_test, test_predictions_stacked)\n",
    "\n",
    "print(\"Stacked Model Performance:\")\n",
    "print(\"Train MSE:\", train_mse_stacked)\n",
    "print(\"Train RMSE:\", train_rmse_stacked)\n",
    "print(\"Train MAE:\", train_mae_stacked)\n",
    "print(\"Train MAPE:\", train_mape_stacked)\n",
    "print(\"Train R2:\", train_r2_stacked)\n",
    "print()\n",
    "print(\"Test MSE:\", test_mse_stacked)\n",
    "print(\"Test RMSE:\", test_rmse_stacked)\n",
    "print(\"Test MAE:\", test_mae_stacked)\n",
    "print(\"Test MAPE:\", test_mape_stacked)\n",
    "print(\"Test R2:\", test_r2_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e476b517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Performance:\n",
      "Train MSE: 0.10225078589283597\n",
      "Train RMSE: 0.31976676796195685\n",
      "Train MAE: 0.19228870063532272\n",
      "Train MAPE: 0.43850735528075546\n",
      "Train R2: 0.8974367865647201\n",
      "\n",
      "Test MSE: 0.16978903667941503\n",
      "Test RMSE: 0.4120546525394599\n",
      "Test MAE: 0.25532792103400387\n",
      "Test MAPE: 0.5052998328062299\n",
      "Test R2: 0.8313563641736781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('xgb', best_model_xgb),\n",
    "    ('bagging', best_model_bagging),\n",
    "    ('Linear Reg',regression_model),\n",
    "    ('SVR',best_model_svr)\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = SVR()\n",
    "\n",
    "# Create the stacked model with regularization\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Fit the stacked model to the training data\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions_stacked = stacked_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the training set\n",
    "train_mse_stacked = mean_squared_error(y_train, train_predictions_stacked)\n",
    "train_rmse_stacked = np.sqrt(train_mse_stacked)\n",
    "train_mae_stacked = mean_absolute_error(y_train, train_predictions_stacked)\n",
    "train_mape_stacked = np.sqrt(mean_absolute_error(y_train, train_predictions_stacked))\n",
    "train_r2_stacked = r2_score(y_train, train_predictions_stacked)\n",
    "\n",
    "\n",
    "# Calculate performance metrics for the test set\n",
    "test_mse_stacked = mean_squared_error(y_test, test_predictions_stacked)\n",
    "test_rmse_stacked = np.sqrt(test_mse_stacked)\n",
    "test_mae_stacked = mean_absolute_error(y_test, test_predictions_stacked)\n",
    "test_mape_stacked = np.sqrt(mean_absolute_error(y_test, test_predictions_stacked))\n",
    "test_r2_stacked = r2_score(y_test, test_predictions_stacked)\n",
    "\n",
    "print(\"Stacked Model Performance:\")\n",
    "print(\"Train MSE:\", train_mse_stacked)\n",
    "print(\"Train RMSE:\", train_rmse_stacked)\n",
    "print(\"Train MAE:\", train_mae_stacked)\n",
    "print(\"Train MAPE:\", train_mape_stacked)\n",
    "print(\"Train R2:\", train_r2_stacked)\n",
    "print()\n",
    "print(\"Test MSE:\", test_mse_stacked)\n",
    "print(\"Test RMSE:\", test_rmse_stacked)\n",
    "print(\"Test MAE:\", test_mae_stacked)\n",
    "print(\"Test MAPE:\", test_mape_stacked)\n",
    "print(\"Test R2:\", test_r2_stacked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57c3e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Performance:\n",
      "Train MSE: 0.1168760563001865\n",
      "Train RMSE: 0.34187140316233894\n",
      "Train MAE: 0.20547542108845576\n",
      "Train MAPE: 0.45329396762857516\n",
      "Train R2: 0.8827668286055719\n",
      "\n",
      "Test MSE: 0.1846000992325944\n",
      "Test RMSE: 0.42965113665926036\n",
      "Test MAE: 0.26710962571375507\n",
      "Test MAPE: 0.5168264947869401\n",
      "Test R2: 0.8166452173984275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('xgb', best_model_xgb),\n",
    "    ('bagging', best_model_bagging),\n",
    "    ('Linear Reg',regression_model),\n",
    "    ('SVR',best_model_svr)\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = XGBRegressor()\n",
    "\n",
    "# Create the stacked model with regularization\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Fit the stacked model to the training data\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions_stacked = stacked_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the training set\n",
    "train_mse_stacked = mean_squared_error(y_train, train_predictions_stacked)\n",
    "train_rmse_stacked = np.sqrt(train_mse_stacked)\n",
    "train_mae_stacked = mean_absolute_error(y_train, train_predictions_stacked)\n",
    "train_mape_stacked = np.sqrt(mean_absolute_error(y_train, train_predictions_stacked))\n",
    "train_r2_stacked = r2_score(y_train, train_predictions_stacked)\n",
    "\n",
    "\n",
    "# Calculate performance metrics for the test set\n",
    "test_mse_stacked = mean_squared_error(y_test, test_predictions_stacked)\n",
    "test_rmse_stacked = np.sqrt(test_mse_stacked)\n",
    "test_mae_stacked = mean_absolute_error(y_test, test_predictions_stacked)\n",
    "test_mape_stacked = np.sqrt(mean_absolute_error(y_test, test_predictions_stacked))\n",
    "test_r2_stacked = r2_score(y_test, test_predictions_stacked)\n",
    "\n",
    "print(\"Stacked Model Performance:\")\n",
    "print(\"Train MSE:\", train_mse_stacked)\n",
    "print(\"Train RMSE:\", train_rmse_stacked)\n",
    "print(\"Train MAE:\", train_mae_stacked)\n",
    "print(\"Train MAPE:\", train_mape_stacked)\n",
    "print(\"Train R2:\", train_r2_stacked)\n",
    "print()\n",
    "print(\"Test MSE:\", test_mse_stacked)\n",
    "print(\"Test RMSE:\", test_rmse_stacked)\n",
    "print(\"Test MAE:\", test_mae_stacked)\n",
    "print(\"Test MAPE:\", test_mape_stacked)\n",
    "print(\"Test R2:\", test_r2_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc9a551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Performance:\n",
      "Train MSE: 0.12574495898825724\n",
      "Train RMSE: 0.3546053566829712\n",
      "Train MAE: 0.22358221713016008\n",
      "Train MAPE: 0.4728448129462351\n",
      "Train R2: 0.8738708269622528\n",
      "\n",
      "Test MSE: 0.19717625917667253\n",
      "Test RMSE: 0.44404533459622403\n",
      "Test MAE: 0.2813481087940218\n",
      "Test MAPE: 0.5304225756828435\n",
      "Test R2: 0.8041538965264727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('xgb', best_model_xgb),\n",
    "    ('bagging', best_model_bagging),\n",
    "    ('Linear Reg',regression_model),\n",
    "    ('SVR',best_model_svr)\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = BaggingRegressor()\n",
    "\n",
    "# Create the stacked model with regularization\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Fit the stacked model to the training data\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions_stacked = stacked_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the training set\n",
    "train_mse_stacked = mean_squared_error(y_train, train_predictions_stacked)\n",
    "train_rmse_stacked = np.sqrt(train_mse_stacked)\n",
    "train_mae_stacked = mean_absolute_error(y_train, train_predictions_stacked)\n",
    "train_mape_stacked = np.sqrt(mean_absolute_error(y_train, train_predictions_stacked))\n",
    "train_r2_stacked = r2_score(y_train, train_predictions_stacked)\n",
    "\n",
    "\n",
    "# Calculate performance metrics for the test set\n",
    "test_mse_stacked = mean_squared_error(y_test, test_predictions_stacked)\n",
    "test_rmse_stacked = np.sqrt(test_mse_stacked)\n",
    "test_mae_stacked = mean_absolute_error(y_test, test_predictions_stacked)\n",
    "test_mape_stacked = np.sqrt(mean_absolute_error(y_test, test_predictions_stacked))\n",
    "test_r2_stacked = r2_score(y_test, test_predictions_stacked)\n",
    "\n",
    "print(\"Stacked Model Performance:\")\n",
    "print(\"Train MSE:\", train_mse_stacked)\n",
    "print(\"Train RMSE:\", train_rmse_stacked)\n",
    "print(\"Train MAE:\", train_mae_stacked)\n",
    "print(\"Train MAPE:\", train_mape_stacked)\n",
    "print(\"Train R2:\", train_r2_stacked)\n",
    "print()\n",
    "print(\"Test MSE:\", test_mse_stacked)\n",
    "print(\"Test RMSE:\", test_rmse_stacked)\n",
    "print(\"Test MAE:\", test_mae_stacked)\n",
    "print(\"Test MAPE:\", test_mape_stacked)\n",
    "print(\"Test R2:\", test_r2_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8927c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
